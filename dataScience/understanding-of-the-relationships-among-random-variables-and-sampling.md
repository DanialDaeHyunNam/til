## Understanding of the Relationships Among Random Variables and Sampling

#### 기댓값
  확률 변수가 따르고 있는 확률 모형, 즉, 확률 밀도 함수를 알고 있을 경우에는 우린 이상적인 상황에서 나올 수 있는 확률을 이용하여 확률 변수의 **평균(mean)**, **기댓값(expectation)** 을 구할 수 있다.

이산 확률 변수의 경우에는<br>
 **E[X]** = **x**<sub><b>i</b></sub>\***P**(**x**<sub><b>i</b></sub>) 로 표현한다. 여기서 P(x)는 확률 질량 함수이자 가중치이며, x<sub><b>i</b></sub>는 가중 평균이다.

이상적인 상황에서 공정한 주사위를 6번 던지면, 전부 다 한번 씩 나옴으로써 1/6의 확률을 보여주면 좋겠지만, 당연히 현실은 그렇게 나올 확률이 더 낮을 것이란 점이었다. 그걸 생각해보면 수식을 정확히 아는 것과 나오게될 샘플을 아는 것은 다르다는 점으로, 마치 하이젠버그의 불확정성의 원리에서 전자의 위치값에 알면 운동값을 알 수 없고, 운동값을 알면 위치값을 알 수 없는 것처럼 그런 관계처럼 느껴지는 것은 상당히 흥미로웠다.

반복 횟수가 높아질수록 물론 확률 모형의 모습이 점점 뚜렷해지긴 하겠지만, 완전히 다가설 수는 없다는 것.

특히 재밌는 식은 아래의 분산에서 나온다.

#### 분산과 표준 편차

확률 분포의 분산은 **Var[X] = E[(X - mu)<sup>2</sup>]** 로 표기한다.
기본적 성질은 아래와 같다.
- 0 또는 양수
- 랜덤 변수가 아닌 상수 값 c에 대해
  - **Var[cX] = c<sup>2</sup>Var[X]**
- **E[X<sup>2</sup>] = mu<sup>2</sup> + Var[X]**

샘플 평균의 분산은 기댓값의 경우였던 **E[X-] = E[X]** 와는 달리, **Var[X-] = (1/N)\*Var[X]** 이다. 즉, 샘플 평균을 취하는 샘플의 수가 커질 수록 샘플 평균 값의 변동이 적어지고, 무한대에 가까워지면 평균값은 일정하다고 볼 수 있기에, 분산은 당연히 0에 가까워지는 것을 수식으로 표현한 것이다.

가장 흥미로운 식은 샘플 분산의 기댓값으로 **E[S<sup>2</sup>] = (N-1/N)\*(Var[X])** 라는 것이다. 즉 편향되지 않은 샘플 분산을 구하려면 샘플 분산값에 (1/N-1)을 곱해주어야 나온다는 점이다. 항상 조금씩 확률 밀도 함수나 질량 함수를 이용해서 계산한 분산 기댓값은 샘플의 분산값보다 크다는 것.
